{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a53086",
   "metadata": {},
   "source": [
    "### makemore: part 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833314ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa68ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34573d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "234e8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the words\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594a50af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 8]) torch.Size([182625])\n",
      "torch.Size([22655, 8]) torch.Size([22655])\n",
      "torch.Size([22866, 8]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d0184d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> y\n",
      ".......y --> u\n",
      "......yu --> h\n",
      ".....yuh --> e\n",
      "....yuhe --> n\n",
      "...yuhen --> g\n",
      "..yuheng --> .\n",
      "........ --> d\n",
      ".......d --> i\n",
      "......di --> o\n",
      ".....dio --> n\n",
      "....dion --> d\n",
      "...diond --> r\n",
      "..diondr --> e\n",
      ".diondre --> .\n",
      "........ --> x\n",
      ".......x --> a\n",
      "......xa --> v\n",
      ".....xav --> i\n",
      "....xavi --> e\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "    print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8d31a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out))/fan_in**0.5 #note: kaiming init\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "    \n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        #parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        #buffers (trained with a running 'momentum update')\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        if self.training:\n",
    "             xmean = x.mean(0, keepdim=True) #batch mean \n",
    "             xvar = x.var(0, keepdim=True) #batch variance\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar +self.eps) #normalize to unit variance\n",
    "        self.out =  self.gamma * xhat + self.beta\n",
    "        # update the buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta] \n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "#         print('Tanh: __call_ ',x)\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return[]\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "class Embedding: \n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "    \n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weight[IX]\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "class FlattenConsecutive:\n",
    "\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T//self.n , C*self.n) # '//' is integer division\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []    \n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "class Sequential:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        # get parameters of all layers and srtech them out into one list \n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d406dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42); #seed rng for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da27173b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22397\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 #the dimensionality of the character embeding vectors\n",
    "n_hidden = 68 #200 the number of the neurons in the  hidden layer of the MLP \n",
    "\n",
    "C = torch.randn((vocab_size, n_embd))\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "\n",
    "#parameter init\n",
    "with torch.no_grad():\n",
    "    model.layers[-1].weight *= 0.1#last layer: make less confident # no Batchnorm used\n",
    "    \n",
    "parameters = model.parameters() \n",
    "print(sum(p.nelement() for p in parameters)) #number of parameters in total \n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91905737",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/mac/Work/ML/nn zero to hero/makemore/makemode_part5.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m e \u001b[39m=\u001b[39m Embedding(vocab_size, n_embd)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m e\u001b[39m.\u001b[39;49mout\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'out'"
     ]
    }
   ],
   "source": [
    "e = Embedding(vocab_size, n_embd)\n",
    "e.out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a8e9af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/mac/Work/ML/nn zero to hero/makemore/makemode_part5.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(layer\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mtuple\u001b[39m(layer\u001b[39m.\u001b[39;49mout\u001b[39m.\u001b[39mshape))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'out'"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5f41526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 2.6704\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/mac/Work/ML/nn zero to hero/makemore/makemode_part5.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m Xb, Yb \u001b[39m=\u001b[39m Xtr[ix], Ytr[ix] \u001b[39m#batch X,Y\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#forward pass \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m logits \u001b[39m=\u001b[39m model(Xb)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(logits, Yb) \u001b[39m# loss function\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#backward pass\u001b[39;00m\n",
      "\u001b[1;32m/Volumes/mac/Work/ML/nn zero to hero/makemore/makemode_part5.ipynb Cell 12\u001b[0m in \u001b[0;36mSequential.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m         x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout \u001b[39m=\u001b[39m x\n\u001b[1;32m    <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout\n",
      "\u001b[1;32m/Volumes/mac/Work/ML/nn zero to hero/makemore/makemode_part5.ipynb Cell 12\u001b[0m in \u001b[0;36mBatchNorm1d.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmomentum \u001b[39m*\u001b[39;49m xmean\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39m*\u001b[39m xvar\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/mac/Work/ML/nn%20zero%20to%20hero/makemore/makemode_part5.ipynb#X30sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "update_to_data_ratio = [] #ud in Andrej's code\n",
    "\n",
    "for i in range(max_steps):\n",
    "    \n",
    "    #minibatch consrtuct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] #batch X,Y\n",
    "    \n",
    "    #forward pass \n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "    \n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    #update: simple SGD\n",
    "    lr = 0.1 if i < 150000 else 0.01 #step learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    #track stats\n",
    "    if i % 10000 == 0: #print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba47297e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x141474d00>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc25f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put layers into eval mode (needed for batchnorm especially)\n",
    "for layer in model.layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e4802b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0167410373687744\n",
      "val 2.081071615219116\n"
     ]
    }
   ],
   "source": [
    "# evaluate the loss\n",
    "torch.no_grad() #this decorator  disables gradient tracking inside pythorc\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte)\n",
    "    }[split]\n",
    "\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f185964a",
   "metadata": {},
   "source": [
    "#### Performance log\n",
    "- original (3 chararcters context + 200 hidden neurons, 12k params): \n",
    "  -> train 2.058, val 2.105\n",
    "- context  3 -> 8 charactrs 22k params: \n",
    "  -> train 1.91, val 2.03\n",
    "- flat -> hierarchical(22k params): trian 1.941 val 2.029 (A results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68c16ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volton.\n",
      "coril.\n",
      "jelonie.\n",
      "ochsida.\n",
      "kayvan.\n",
      "anya.\n",
      "perstika.\n",
      "malailah.\n",
      "isair.\n",
      "jaxseen.\n",
      "ahmhia.\n",
      "prak.\n",
      "lodyxrid.\n",
      "merrose.\n",
      "jotty.\n",
      "demalyse.\n",
      "juliana.\n",
      "thrkira.\n",
      "raithet.\n",
      "auliyah.\n"
     ]
    }
   ],
   "source": [
    "# sample  from the model\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all...\n",
    "    \n",
    "    while True: \n",
    "        # forward pass the neural net\n",
    "        logits = model(torch.tensor([context]))\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # sample from the distribution\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "        # shift he context window and track the samples\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        # if we sample the special '.' token, break\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(itos[i] for i in out)) #decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b78e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd4d08471f8b52ae0e750abaccdc0c76dbde5ebab3a4687451f54925332cd794"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
